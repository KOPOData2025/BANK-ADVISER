"""
ìŒì„± íŠ¹ì§• ìºì‹± ì‹œìŠ¤í…œ
ì„±ëŠ¥ ìµœì í™”: MFCC íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ ìºì‹±, ë¹„ë™ê¸° ì²˜ë¦¬, ë°°ì¹˜ ì²˜ë¦¬
"""

import redis
import pickle
import hashlib
import asyncio
import concurrent.futures
import multiprocessing
import numpy as np
import librosa
import logging
from typing import Optional, Dict, List, Tuple
from datetime import datetime, timedelta
import os
import tempfile
import subprocess
import base64
from scipy.io import wavfile as scipy_wavfile

logger = logging.getLogger(__name__)

class VoiceFeatureCache:
    """ìŒì„± íŠ¹ì§• ìºì‹± í´ë˜ìŠ¤"""
    
    def __init__(self, redis_host='localhost', redis_port=6379, redis_db=0):
        self.redis_client = None
        self.memory_cache = {}  # ë©”ëª¨ë¦¬ ìºì‹œ (Redis ëŒ€ì‹  ì‚¬ìš©)
        self.cache_timestamps = {}
        self.cache_ttl = 3600  # 1ì‹œê°„
        
        # Redis ì—°ê²° ì‹œë„
        try:
            self.redis_client = redis.Redis(
                host=redis_host, 
                port=redis_port, 
                db=redis_db, 
                decode_responses=False
            )
            self.redis_client.ping()
            logger.info("âœ… Redis ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨, ë©”ëª¨ë¦¬ ìºì‹œ ì‚¬ìš©: {e}")
            self.redis_client = None
    
    def _generate_audio_hash(self, audio_data: bytes) -> str:
        """ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ í•´ì‹œ ìƒì„±"""
        return hashlib.md5(audio_data).hexdigest()
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        if self.redis_client:
            return self.redis_client.exists(cache_key)
        else:
            timestamp = self.cache_timestamps.get(cache_key)
            if timestamp is None:
                return False
            return (datetime.now() - timestamp).seconds < self.cache_ttl
    
    def get_cached_features(self, audio_hash: str) -> Optional[np.ndarray]:
        """ìºì‹œëœ ìŒì„± íŠ¹ì§• ì¡°íšŒ"""
        cache_key = f"voice_features:{audio_hash}"
        
        if self.redis_client:
            try:
                cached_data = self.redis_client.get(cache_key)
                if cached_data:
                    logger.info(f"âœ… Redis ìºì‹œ íˆíŠ¸: {audio_hash}")
                    return pickle.loads(cached_data)
            except Exception as e:
                logger.error(f"âŒ Redis ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if cache_key in self.memory_cache and self._is_cache_valid(cache_key):
            logger.info(f"âœ… ë©”ëª¨ë¦¬ ìºì‹œ íˆíŠ¸: {audio_hash}")
            return self.memory_cache[cache_key]
        
        return None
    
    def cache_features(self, audio_hash: str, features: np.ndarray) -> None:
        """ìŒì„± íŠ¹ì§• ìºì‹±"""
        cache_key = f"voice_features:{audio_hash}"
        
        if self.redis_client:
            try:
                self.redis_client.setex(
                    cache_key, 
                    self.cache_ttl, 
                    pickle.dumps(features)
                )
                logger.info(f"âœ… Redis ìºì‹œ ì €ì¥: {audio_hash}")
            except Exception as e:
                logger.error(f"âŒ Redis ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
        self.memory_cache[cache_key] = features
        self.cache_timestamps[cache_key] = datetime.now()
        logger.info(f"âœ… ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥: {audio_hash}")
    
    def extract_audio_features_cached(self, audio_data: bytes) -> Optional[np.ndarray]:
        """ìºì‹±ëœ ìŒì„± íŠ¹ì§• ì¶”ì¶œ"""
        audio_hash = self._generate_audio_hash(audio_data)
        
        # ìºì‹œ í™•ì¸
        cached_features = self.get_cached_features(audio_hash)
        if cached_features is not None:
            return cached_features
        
        # íŠ¹ì§• ì¶”ì¶œ
        logger.info(f"ğŸ”§ ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì‹œì‘: {audio_hash}")
        features = self._extract_mfcc_features(audio_data)
        
        if features is not None:
            # ìºì‹œì— ì €ì¥
            self.cache_features(audio_hash, features)
            logger.info(f"âœ… ìŒì„± íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {audio_hash}")
        
        return features
    
    def _extract_mfcc_features(self, audio_data: bytes) -> Optional[np.ndarray]:
        """MFCC íŠ¹ì§• ì¶”ì¶œ"""
        temp_file = None
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                f.write(audio_data)
                temp_file = f.name
            
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            y, sr = librosa.load(temp_file, sr=16000)
            
            # MFCC ì¶”ì¶œ
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            mfccs_mean = np.mean(mfccs, axis=1)
            
            return mfccs_mean
            
        except Exception as e:
            logger.error(f"âŒ MFCC íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
        finally:
            if temp_file and os.path.exists(temp_file):
                os.remove(temp_file)

class AsyncVoiceProcessor:
    """ë¹„ë™ê¸° ìŒì„± ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, max_workers=4):
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)
        self.voice_cache = VoiceFeatureCache()
    
    async def process_audio_async(self, audio_data: bytes) -> Optional[np.ndarray]:
        """ë¹„ë™ê¸° ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
        loop = asyncio.get_event_loop()
        
        try:
            features = await loop.run_in_executor(
                self.executor, 
                self.voice_cache.extract_audio_features_cached, 
                audio_data
            )
            return features
        except Exception as e:
            logger.error(f"âŒ ë¹„ë™ê¸° ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    async def batch_process_audio(self, audio_list: List[bytes]) -> List[Optional[np.ndarray]]:
        """ë°°ì¹˜ ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
        tasks = [self.process_audio_async(audio_data) for audio_data in audio_list]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {result}")
                processed_results.append(None)
            else:
                processed_results.append(result)
        
        return processed_results
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.executor.shutdown(wait=True)

class VoiceSimilarityCalculator:
    """ìŒì„± ìœ ì‚¬ë„ ê³„ì‚°ê¸° (ìµœì í™”)"""
    
    def __init__(self):
        self.similarity_cache = {}
        self.cache_ttl = 1800  # 30ë¶„
    
    def calculate_similarity_cached(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """ìºì‹±ëœ ìœ ì‚¬ë„ ê³„ì‚°"""
        if features1 is None or features2 is None:
            return 0.0
        
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._generate_similarity_key(features1, features2)
        
        # ìºì‹œ í™•ì¸
        if cache_key in self.similarity_cache:
            timestamp, similarity = self.similarity_cache[cache_key]
            if (datetime.now() - timestamp).seconds < self.cache_ttl:
                logger.info(f"âœ… ìœ ì‚¬ë„ ìºì‹œ íˆíŠ¸: {cache_key}")
                return similarity
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        try:
            from sklearn.metrics.pairwise import cosine_similarity
            similarity = cosine_similarity([features1], [features2])[0][0]
            
            # ìºì‹œì— ì €ì¥
            self.similarity_cache[cache_key] = (datetime.now(), similarity)
            logger.info(f"âœ… ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ: {similarity:.4f}")
            
            return similarity
        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _generate_similarity_key(self, features1: np.ndarray, features2: np.ndarray) -> str:
        """ìœ ì‚¬ë„ ê³„ì‚°ìš© ìºì‹œ í‚¤ ìƒì„±"""
        hash1 = hashlib.md5(features1.tobytes()).hexdigest()[:8]
        hash2 = hashlib.md5(features2.tobytes()).hexdigest()[:8]
        return f"similarity:{hash1}:{hash2}"
    
    def cleanup_expired_cache(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        current_time = datetime.now()
        expired_keys = [
            key for key, (timestamp, _) in self.similarity_cache.items()
            if (current_time - timestamp).seconds >= self.cache_ttl
        ]
        
        for key in expired_keys:
            del self.similarity_cache[key]
        
        if expired_keys:
            logger.info(f"ğŸ§¹ ë§Œë£Œëœ ìœ ì‚¬ë„ ìºì‹œ ì •ë¦¬: {len(expired_keys)}ê°œ í•­ëª© ì œê±°")

class VoicePerformanceOptimizer:
    """ìŒì„± ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™” ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.async_processor = AsyncVoiceProcessor()
        self.similarity_calculator = VoiceSimilarityCalculator()
        self.performance_stats = {
            'cache_hits': 0,
            'cache_misses': 0,
            'total_requests': 0,
            'average_processing_time': 0.0
        }
    
    async def process_voice_with_optimization(self, audio_data: bytes) -> Dict:
        """ìµœì í™”ëœ ìŒì„± ì²˜ë¦¬"""
        start_time = datetime.now()
        self.performance_stats['total_requests'] += 1
        
        try:
            # ë¹„ë™ê¸° íŠ¹ì§• ì¶”ì¶œ
            features = await self.async_processor.process_audio_async(audio_data)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            self._update_performance_stats(processing_time)
            
            return {
                'success': True,
                'features': features,
                'processing_time': processing_time,
                'audio_hash': hashlib.md5(audio_data).hexdigest()
            }
            
        except Exception as e:
            logger.error(f"âŒ ìµœì í™”ëœ ìŒì„± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e),
                'processing_time': (datetime.now() - start_time).total_seconds()
            }
    
    def calculate_voice_similarity_optimized(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """ìµœì í™”ëœ ìŒì„± ìœ ì‚¬ë„ ê³„ì‚°"""
        return self.similarity_calculator.calculate_similarity_cached(features1, features2)
    
    def _update_performance_stats(self, processing_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        current_avg = self.performance_stats['average_processing_time']
        total_requests = self.performance_stats['total_requests']
        
        # ì´ë™ í‰ê·  ê³„ì‚°
        self.performance_stats['average_processing_time'] = (
            (current_avg * (total_requests - 1) + processing_time) / total_requests
        )
    
    def get_performance_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        cache_hit_rate = 0.0
        if self.performance_stats['total_requests'] > 0:
            cache_hit_rate = (
                self.performance_stats['cache_hits'] / 
                self.performance_stats['total_requests']
            )
        
        return {
            **self.performance_stats,
            'cache_hit_rate': cache_hit_rate,
            'memory_cache_size': len(self.async_processor.voice_cache.memory_cache),
            'similarity_cache_size': len(self.similarity_calculator.similarity_cache)
        }
    
    def cleanup_all_caches(self):
        """ëª¨ë“  ìºì‹œ ì •ë¦¬"""
        self.similarity_calculator.cleanup_expired_cache()
        logger.info("ğŸ§¹ ëª¨ë“  ìŒì„± ì²˜ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.async_processor.close()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
voice_optimizer = VoicePerformanceOptimizer()

def get_voice_optimizer() -> VoicePerformanceOptimizer:
    """ìŒì„± ìµœì í™”ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return voice_optimizer

